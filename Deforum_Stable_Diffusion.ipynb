{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByGXyiHZWM_q"
   },
   "source": [
    "# **Deforum Stable Diffusion (v0.7.1)**\n",
    "**Help keep these resources free for everyone**, please consider supporting us on [Patreon](https://www.patreon.com/deforum). Every bit of support is deeply appreciated!\n",
    "\n",
    "- **Looking for a latest in Deforum development?** Check out the [Deforum Automatic1111 Extension](https://github.com/deforum-art/sd-webui-deforum)\n",
    "\n",
    "- **Something not working properly?** Use our github page to submit a [New Issue](https://github.com/deforum-art/deforum-stable-diffusion/issues)\n",
    "\n",
    "- **Need help?** For support please join our community [Discord](https://discord.gg/deforum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "IJjzzkKlWM_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4080, 16376 MiB, 15107 MiB\r\n"
     ]
    }
   ],
   "source": [
    "#@markdown **NVIDIA GPU**\n",
    "import subprocess, os, sys\n",
    "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "print(f\"{sub_p_res[:-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UA8-efH-WM_t"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "vohUiWo-I2HQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..skipping setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\santi\\anaconda3\\envs\\deforum_sd\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#@markdown **Environment Setup**\n",
    "import subprocess, time, gc, os, sys\n",
    "\n",
    "def setup_environment():\n",
    "    try:\n",
    "        ipy = get_ipython()\n",
    "    except:\n",
    "        ipy = 'could not get_ipython'\n",
    "    \n",
    "    if 'google.colab' in str(ipy):\n",
    "        start_time = time.time()\n",
    "        packages = [\n",
    "            'triton xformers==0.0.20',\n",
    "            'einops==0.4.1 pytorch-lightning==1.7.7 torchdiffeq==0.2.3 torchsde==0.2.5',\n",
    "            'ftfy timm transformers open-clip-torch omegaconf torchmetrics==0.11.4',\n",
    "            'safetensors kornia accelerate jsonmerge matplotlib resize-right',\n",
    "            'scikit-learn numpngw pydantic'\n",
    "        ]\n",
    "        for package in packages:\n",
    "            print(f\"..installing {package}\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + package.split())\n",
    "        if not os.path.exists(\"deforum-stable-diffusion\"):\n",
    "            subprocess.check_call(['git', 'clone', '-b', '0.7.1', 'https://github.com/deforum-art/deforum-stable-diffusion.git'])\n",
    "        else:\n",
    "            print(f\"..deforum-stable-diffusion already exists\")\n",
    "        with open('deforum-stable-diffusion/src/k_diffusion/__init__.py', 'w') as f:\n",
    "            f.write('')\n",
    "        sys.path.extend(['deforum-stable-diffusion/','deforum-stable-diffusion/src',])\n",
    "        end_time = time.time()\n",
    "        print(f\"..environment set up in {end_time-start_time:.0f} seconds\")\n",
    "    else:\n",
    "        sys.path.extend(['src'])\n",
    "        print(\"..skipping setup\")\n",
    "\n",
    "setup_environment()\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import clip\n",
    "from IPython import display\n",
    "from types import SimpleNamespace\n",
    "from helpers.save_images import get_output_folder\n",
    "from helpers.settings import load_args\n",
    "from helpers.render import render_animation, render_input_video, render_image_batch, render_interpolation\n",
    "from helpers.model_load import make_linear_decode, load_model, get_model_output_paths\n",
    "from helpers.aesthetics import load_aesthetics_model\n",
    "from helpers.prompts import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "tQPlBfq9fIj8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_path: C:\\Users\\santi\\Documents\\deforum-stable-diffusion\\models\n",
      "output_path: C:\\Users\\santi\\Documents\\deforum-stable-diffusion\\outputs\n"
     ]
    }
   ],
   "source": [
    "#@markdown **Path Setup**\n",
    "\n",
    "def PathSetup():\n",
    "    models_path = \"models\" #@param {type:\"string\"}\n",
    "    configs_path = \"configs\" #@param {type:\"string\"}\n",
    "    output_path = \"outputs\" #@param {type:\"string\"}\n",
    "    mount_google_drive = True #@param {type:\"boolean\"}\n",
    "    models_path_gdrive = \"/content/drive/MyDrive/AI/models\" #@param {type:\"string\"}\n",
    "    output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\" #@param {type:\"string\"}\n",
    "    return locals()\n",
    "\n",
    "root = SimpleNamespace(**PathSetup())\n",
    "root.models_path, root.output_path = get_model_output_paths(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "232_xKcCfIj9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_path: C:\\Users\\santi\\Documents\\deforum-stable-diffusion\\configs\\v1-inference.yaml\n",
      "ckpt_path: C:\\Users\\santi\\Documents\\deforum-stable-diffusion\\models\\Protogen_V2.2.ckpt\n",
      "..checking sha256\n",
      "..hash is correct\n",
      "..loading model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m()\n\u001b[0;32m     11\u001b[0m root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(ModelSetup())\n\u001b[1;32m---> 12\u001b[0m root\u001b[38;5;241m.\u001b[39mmodel, root\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_on_run_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_sha256\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\deforum-stable-diffusion\\helpers\\model_load.py:253\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(root, load_on_run_all, check_sha256, map_location)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_on_run_all \u001b[38;5;129;01mand\u001b[39;00m ckpt_valid:\n\u001b[0;32m    252\u001b[0m     local_config \u001b[38;5;241m=\u001b[39m OmegaConf\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_config_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 253\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mckpt_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    255\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\Documents\\deforum-stable-diffusion\\helpers\\model_load.py:230\u001b[0m, in \u001b[0;36mload_model.<locals>.load_model_from_config\u001b[1;34m(config, ckpt, verbose, device, print_flag, map_location)\u001b[0m\n\u001b[0;32m    228\u001b[0m     pl_sd \u001b[38;5;241m=\u001b[39m safetensors\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload_file(ckpt, device\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     pl_sd \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m     sd \u001b[38;5;241m=\u001b[39m pl_sd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[0;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:1049\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1047\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1048\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1049\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1051\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:1019\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[0;32m   1018\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1019\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m    997\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39m_UntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_untyped()\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[1;32m-> 1001\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1002\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:970\u001b[0m, in \u001b[0;36m_get_restore_location.<locals>.restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_location\u001b[39m(storage, location):\n\u001b[1;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_restore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deforum_sd\\lib\\site-packages\\torch\\serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "#@markdown **Model Setup**\n",
    "\n",
    "def ModelSetup():\n",
    "    map_location = \"cuda\" #@param [\"cpu\", \"cuda\"]\n",
    "    model_config = \"v1-inference.yaml\" #@param [\"custom\",\"v2-inference.yaml\",\"v2-inference-v.yaml\",\"v1-inference.yaml\"]\n",
    "    model_checkpoint =  \"Protogen_V2.2.ckpt\" #@param [\"custom\",\"v2-1_768-ema-pruned.ckpt\",\"v2-1_512-ema-pruned.ckpt\",\"768-v-ema.ckpt\",\"512-base-ema.ckpt\",\"Protogen_V2.2.ckpt\",\"v1-5-pruned.ckpt\",\"v1-5-pruned-emaonly.ckpt\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"wd-v1-3-float16.ckpt\"]\n",
    "    custom_config_path = \"\" #@param {type:\"string\"}\n",
    "    custom_checkpoint_path = \"\" #@param {type:\"string\"}\n",
    "    return locals()\n",
    "\n",
    "root.__dict__.update(ModelSetup())\n",
    "root.model, root.device = load_model(root, load_on_run_all=True, check_sha256=True, map_location=root.map_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JxwhBwtWM_t"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "E0tJVYA4WM_u"
   },
   "outputs": [],
   "source": [
    "def DeforumAnimArgs():\n",
    "\n",
    "    #@markdown ####**Animation:**\n",
    "    animation_mode = 'None' #@param ['None', '2D', '3D', 'Video Input', 'Interpolation'] {type:'string'}\n",
    "    max_frames = 1000 #@param {type:\"number\"}\n",
    "    border = 'replicate' #@param ['wrap', 'replicate'] {type:'string'}\n",
    "\n",
    "    #@markdown ####**Motion Parameters:**\n",
    "    angle = \"0:(0)\"#@param {type:\"string\"}\n",
    "    zoom = \"0:(1.04)\"#@param {type:\"string\"}\n",
    "    translation_x = \"0:(10*sin(2*3.14*t/10))\"#@param {type:\"string\"}\n",
    "    translation_y = \"0:(0)\"#@param {type:\"string\"}\n",
    "    translation_z = \"0:(10)\"#@param {type:\"string\"}\n",
    "    rotation_3d_x = \"0:(0)\"#@param {type:\"string\"}\n",
    "    rotation_3d_y = \"0:(0)\"#@param {type:\"string\"}\n",
    "    rotation_3d_z = \"0:(0)\"#@param {type:\"string\"}\n",
    "    flip_2d_perspective = False #@param {type:\"boolean\"}\n",
    "    perspective_flip_theta = \"0:(0)\"#@param {type:\"string\"}\n",
    "    perspective_flip_phi = \"0:(t%15)\"#@param {type:\"string\"}\n",
    "    perspective_flip_gamma = \"0:(0)\"#@param {type:\"string\"}\n",
    "    perspective_flip_fv = \"0:(53)\"#@param {type:\"string\"}\n",
    "    noise_schedule = \"0: (0.02)\"#@param {type:\"string\"}\n",
    "    strength_schedule = \"0: (0.65)\"#@param {type:\"string\"}\n",
    "    contrast_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
    "    hybrid_comp_alpha_schedule = \"0:(1)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_blend_alpha_schedule = \"0:(0.5)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_contrast_schedule = \"0:(1)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_auto_contrast_cutoff_high_schedule =  \"0:(100)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_auto_contrast_cutoff_low_schedule =  \"0:(0)\" #@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Sampler Scheduling:**\n",
    "    enable_schedule_samplers = False #@param {type:\"boolean\"}\n",
    "    sampler_schedule = \"0:('euler'),10:('dpm2'),20:('dpm2_ancestral'),30:('heun'),40:('euler'),50:('euler_ancestral'),60:('dpm_fast'),70:('dpm_adaptive'),80:('dpmpp_2s_a'),90:('dpmpp_2m')\" #@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Unsharp mask (anti-blur) Parameters:**\n",
    "    kernel_schedule = \"0: (5)\"#@param {type:\"string\"}\n",
    "    sigma_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
    "    amount_schedule = \"0: (0.2)\"#@param {type:\"string\"}\n",
    "    threshold_schedule = \"0: (0.0)\"#@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Coherence:**\n",
    "    color_coherence = 'Match Frame 0 LAB' #@param ['None', 'Match Frame 0 HSV', 'Match Frame 0 LAB', 'Match Frame 0 RGB', 'Video Input'] {type:'string'}\n",
    "    color_coherence_video_every_N_frames = 1 #@param {type:\"integer\"}\n",
    "    color_force_grayscale = False #@param {type:\"boolean\"}\n",
    "    diffusion_cadence = '1' #@param ['1','2','3','4','5','6','7','8'] {type:'string'}\n",
    "\n",
    "    #@markdown ####**3D Depth Warping:**\n",
    "    use_depth_warping = True #@param {type:\"boolean\"}\n",
    "    midas_weight = 0.3#@param {type:\"number\"}\n",
    "    near_plane = 200\n",
    "    far_plane = 10000\n",
    "    fov = 40#@param {type:\"number\"}\n",
    "    padding_mode = 'border'#@param ['border', 'reflection', 'zeros'] {type:'string'}\n",
    "    sampling_mode = 'bicubic'#@param ['bicubic', 'bilinear', 'nearest'] {type:'string'}\n",
    "    save_depth_maps = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown ####**Video Input:**\n",
    "    video_init_path ='/content/video_in.mp4'#@param {type:\"string\"}\n",
    "    extract_nth_frame = 1#@param {type:\"number\"}\n",
    "    overwrite_extracted_frames = True #@param {type:\"boolean\"}\n",
    "    use_mask_video = False #@param {type:\"boolean\"}\n",
    "    video_mask_path ='/content/video_in.mp4'#@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Hybrid Video for 2D/3D Animation Mode:**\n",
    "    hybrid_generate_inputframes = False #@param {type:\"boolean\"}\n",
    "    hybrid_use_first_frame_as_init_image = True #@param {type:\"boolean\"}\n",
    "    hybrid_motion = \"None\" #@param ['None','Optical Flow','Perspective','Affine']\n",
    "    hybrid_motion_use_prev_img = False #@param {type:\"boolean\"}\n",
    "    hybrid_flow_method = \"DIS Medium\" #@param ['DenseRLOF','DIS Medium','Farneback','SF']\n",
    "    hybrid_composite = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_mask_type = \"None\" #@param ['None', 'Depth', 'Video Depth', 'Blend', 'Difference']\n",
    "    hybrid_comp_mask_inverse = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_mask_equalize = \"None\" #@param  ['None','Before','After','Both']\n",
    "    hybrid_comp_mask_auto_contrast = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_save_extra_frames = False #@param {type:\"boolean\"}\n",
    "    hybrid_use_video_as_mse_image = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown ####**Interpolation:**\n",
    "    interpolate_key_frames = False #@param {type:\"boolean\"}\n",
    "    interpolate_x_frames = 20 #@param {type:\"number\"}\n",
    "    \n",
    "    #@markdown ####**Resume Animation:**\n",
    "    resume_from_timestring = False #@param {type:\"boolean\"}\n",
    "    resume_timestring = \"20220829210106\" #@param {type:\"string\"}\n",
    "\n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9fly1RIWM_u"
   },
   "outputs": [],
   "source": [
    "# prompts\n",
    "prompts = {\n",
    "    0: \"a beautiful lake by Asher Brown Durand, trending on Artstation\",\n",
    "    10: \"a beautiful portrait of a woman by Artgerm, trending on Artstation\",\n",
    "}\n",
    "\n",
    "neg_prompts = {\n",
    "    0: \"mountain\",\n",
    "}\n",
    "\n",
    "# can be a string, list, or dictionary\n",
    "#prompts = [\n",
    "#    \"a beautiful lake by Asher Brown Durand, trending on Artstation\",\n",
    "#    \"a beautiful portrait of a woman by Artgerm, trending on Artstation\",\n",
    "#]\n",
    "#prompts = \"a beautiful lake by Asher Brown Durand, trending on Artstation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "XVzhbmizWM_u"
   },
   "outputs": [],
   "source": [
    "#@markdown **Load Settings**\n",
    "override_settings_with_file = False #@param {type:\"boolean\"}\n",
    "settings_file = \"custom\" #@param [\"custom\", \"512x512_aesthetic_0.json\",\"512x512_aesthetic_1.json\",\"512x512_colormatch_0.json\",\"512x512_colormatch_1.json\",\"512x512_colormatch_2.json\",\"512x512_colormatch_3.json\"]\n",
    "custom_settings_file = \"/content/drive/MyDrive/Settings.txt\"#@param {type:\"string\"}\n",
    "\n",
    "def DeforumArgs():\n",
    "    #@markdown **Image Settings**\n",
    "    W = 512 #@param\n",
    "    H = 512 #@param\n",
    "    W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
    "    bit_depth_output = 8 #@param [8, 16, 32] {type:\"raw\"}\n",
    "\n",
    "    #@markdown **Sampling Settings**\n",
    "    seed = -1 #@param\n",
    "    sampler = 'euler_ancestral' #@param [\"klms\",\"dpm2\",\"dpm2_ancestral\",\"heun\",\"euler\",\"euler_ancestral\",\"plms\", \"ddim\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_a\", \"dpmpp_2m\"]\n",
    "    steps = 50 #@param\n",
    "    scale = 7 #@param\n",
    "    ddim_eta = 0.0 #@param\n",
    "    dynamic_threshold = None\n",
    "    static_threshold = None   \n",
    "\n",
    "    #@markdown **Save & Display Settings**\n",
    "    save_samples = True #@param {type:\"boolean\"}\n",
    "    save_settings = True #@param {type:\"boolean\"}\n",
    "    display_samples = True #@param {type:\"boolean\"}\n",
    "    save_sample_per_step = False #@param {type:\"boolean\"}\n",
    "    show_sample_per_step = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown **Batch Settings**\n",
    "    n_batch = 1 #@param\n",
    "    n_samples = 1 #@param\n",
    "    batch_name = \"StableFun\" #@param {type:\"string\"}\n",
    "    filename_format = \"{timestring}_{index}_{prompt}.png\" #@param [\"{timestring}_{index}_{seed}.png\",\"{timestring}_{index}_{prompt}.png\"]\n",
    "    seed_behavior = \"iter\" #@param [\"iter\",\"fixed\",\"random\",\"ladder\",\"alternate\"]\n",
    "    seed_iter_N = 1 #@param {type:'integer'}\n",
    "    make_grid = False #@param {type:\"boolean\"}\n",
    "    grid_rows = 2 #@param \n",
    "    outdir = get_output_folder(root.output_path, batch_name)\n",
    "\n",
    "    #@markdown **Init Settings**\n",
    "    use_init = False #@param {type:\"boolean\"}\n",
    "    strength = 0.65 #@param {type:\"number\"}\n",
    "    strength_0_no_init = True # Set the strength to 0 automatically when no init image is used\n",
    "    init_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
    "    add_init_noise = False #@param {type:\"boolean\"}\n",
    "    init_noise = 0.01 #@param\n",
    "    # Whiter areas of the mask are areas that change more\n",
    "    use_mask = False #@param {type:\"boolean\"}\n",
    "    use_alpha_as_mask = False # use the alpha channel of the init image as the mask\n",
    "    mask_file = \"https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg\" #@param {type:\"string\"}\n",
    "    invert_mask = False #@param {type:\"boolean\"}\n",
    "    # Adjust mask image, 1.0 is no adjustment. Should be positive numbers.\n",
    "    mask_brightness_adjust = 1.0  #@param {type:\"number\"}\n",
    "    mask_contrast_adjust = 1.0  #@param {type:\"number\"}\n",
    "    # Overlay the masked image at the end of the generation so it does not get degraded by encoding and decoding\n",
    "    overlay_mask = True  # {type:\"boolean\"}\n",
    "    # Blur edges of final overlay mask, if used. Minimum = 0 (no blur)\n",
    "    mask_overlay_blur = 5 # {type:\"number\"}\n",
    "\n",
    "    #@markdown **Exposure/Contrast Conditional Settings**\n",
    "    mean_scale = 0 #@param {type:\"number\"}\n",
    "    var_scale = 0 #@param {type:\"number\"}\n",
    "    exposure_scale = 0 #@param {type:\"number\"}\n",
    "    exposure_target = 0.5 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **Color Match Conditional Settings**\n",
    "    colormatch_scale = 0 #@param {type:\"number\"}\n",
    "    colormatch_image = \"https://www.saasdesign.io/wp-content/uploads/2021/02/palette-3-min-980x588.png\" #@param {type:\"string\"}\n",
    "    colormatch_n_colors = 4 #@param {type:\"number\"}\n",
    "    ignore_sat_weight = 0 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **CLIP\\Aesthetics Conditional Settings**\n",
    "    clip_name = 'ViT-L/14' #@param ['ViT-L/14', 'ViT-L/14@336px', 'ViT-B/16', 'ViT-B/32']\n",
    "    clip_scale = 0 #@param {type:\"number\"}\n",
    "    aesthetics_scale = 0 #@param {type:\"number\"}\n",
    "    cutn = 1 #@param {type:\"number\"}\n",
    "    cut_pow = 0.0001 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **Other Conditional Settings**\n",
    "    init_mse_scale = 0 #@param {type:\"number\"}\n",
    "    init_mse_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
    "    blue_scale = 0 #@param {type:\"number\"}\n",
    "    \n",
    "    #@markdown **Conditional Gradient Settings**\n",
    "    gradient_wrt = 'x0_pred' #@param [\"x\", \"x0_pred\"]\n",
    "    gradient_add_to = 'both' #@param [\"cond\", \"uncond\", \"both\"]\n",
    "    decode_method = 'linear' #@param [\"autoencoder\",\"linear\"]\n",
    "    grad_threshold_type = 'dynamic' #@param [\"dynamic\", \"static\", \"mean\", \"schedule\"]\n",
    "    clamp_grad_threshold = 0.2 #@param {type:\"number\"}\n",
    "    clamp_start = 0.2 #@param\n",
    "    clamp_stop = 0.01 #@param\n",
    "    grad_inject_timing = list(range(1,10)) #@param\n",
    "\n",
    "    #@markdown **Speed vs VRAM Settings**\n",
    "    cond_uncond_sync = True #@param {type:\"boolean\"}\n",
    "    precision = 'autocast' \n",
    "    C = 4\n",
    "    f = 8\n",
    "\n",
    "    cond_prompt = \"\"\n",
    "    cond_prompts = \"\"\n",
    "    uncond_prompt = \"\"\n",
    "    uncond_prompts = \"\"\n",
    "    timestring = \"\"\n",
    "    init_latent = None\n",
    "    init_sample = None\n",
    "    init_sample_raw = None\n",
    "    mask_sample = None\n",
    "    init_c = None\n",
    "    seed_internal = 0\n",
    "\n",
    "    return locals()\n",
    "\n",
    "args_dict = DeforumArgs()\n",
    "anim_args_dict = DeforumAnimArgs()\n",
    "\n",
    "if override_settings_with_file:\n",
    "    load_args(args_dict, anim_args_dict, settings_file, custom_settings_file, verbose=False)\n",
    "\n",
    "args = SimpleNamespace(**args_dict)\n",
    "anim_args = SimpleNamespace(**anim_args_dict)\n",
    "\n",
    "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
    "args.strength = max(0.0, min(1.0, args.strength))\n",
    "\n",
    "# Load clip model if using clip guidance\n",
    "if (args.clip_scale > 0) or (args.aesthetics_scale > 0):\n",
    "    root.clip_model = clip.load(args.clip_name, jit=False)[0].eval().requires_grad_(False).to(root.device)\n",
    "    if (args.aesthetics_scale > 0):\n",
    "        root.aesthetics_model = load_aesthetics_model(args, root)\n",
    "\n",
    "if args.seed == -1:\n",
    "    args.seed = random.randint(0, 2**32 - 1)\n",
    "if not args.use_init:\n",
    "    args.init_image = None\n",
    "if args.sampler == 'plms' and (args.use_init or anim_args.animation_mode != 'None'):\n",
    "    print(f\"Init images aren't supported with PLMS yet, switching to KLMS\")\n",
    "    args.sampler = 'klms'\n",
    "if args.sampler != 'ddim':\n",
    "    args.ddim_eta = 0\n",
    "\n",
    "if anim_args.animation_mode == 'None':\n",
    "    anim_args.max_frames = 1\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    args.use_init = True\n",
    "\n",
    "# clean up unused memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# get prompts\n",
    "cond, uncond = Prompts(prompt=prompts,neg_prompt=neg_prompts).as_dict()\n",
    "\n",
    "# dispatch to appropriate renderer\n",
    "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
    "    render_animation(root, anim_args, args, cond, uncond)\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    render_input_video(root, anim_args, args, cond, uncond)\n",
    "elif anim_args.animation_mode == 'Interpolation':\n",
    "    render_interpolation(root, anim_args, args, cond, uncond)\n",
    "else:\n",
    "    render_image_batch(root, args, cond, uncond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ88kZ2-WM_v"
   },
   "source": [
    "# Create Video From Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "YDoi7at9avqC"
   },
   "outputs": [],
   "source": [
    "#@markdown **New Version**\n",
    "skip_video_for_run_all = True #@param {type: 'boolean'}\n",
    "create_gif = False #@param {type: 'boolean'}\n",
    "\n",
    "if skip_video_for_run_all == True:\n",
    "    print('Skipping video creation, uncheck skip_video_for_run_all if you want to run it')\n",
    "else:\n",
    "\n",
    "    from helpers.ffmpeg_helpers import get_extension_maxframes, get_auto_outdir_timestring, get_ffmpeg_path, make_mp4_ffmpeg, make_gif_ffmpeg, patrol_cycle\n",
    "\n",
    "    def ffmpegArgs():\n",
    "        ffmpeg_mode = \"auto\" #@param [\"auto\",\"manual\",\"timestring\"]\n",
    "        ffmpeg_outdir = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_timestring = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_image_path = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_mp4_path = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_gif_path = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_extension = \"png\" #@param {type:\"string\"}\n",
    "        ffmpeg_maxframes = 200 #@param\n",
    "        ffmpeg_fps = 12 #@param\n",
    "\n",
    "        # determine auto paths\n",
    "        if ffmpeg_mode == 'auto':\n",
    "            ffmpeg_outdir, ffmpeg_timestring = get_auto_outdir_timestring(args,ffmpeg_mode)\n",
    "        if ffmpeg_mode in [\"auto\",\"timestring\"]:\n",
    "            ffmpeg_extension, ffmpeg_maxframes = get_extension_maxframes(args,ffmpeg_outdir,ffmpeg_timestring)\n",
    "            ffmpeg_image_path, ffmpeg_mp4_path, ffmpeg_gif_path = get_ffmpeg_path(ffmpeg_outdir, ffmpeg_timestring, ffmpeg_extension)\n",
    "        return locals()\n",
    "\n",
    "    ffmpeg_args_dict = ffmpegArgs()\n",
    "    ffmpeg_args = SimpleNamespace(**ffmpeg_args_dict)\n",
    "    make_mp4_ffmpeg(ffmpeg_args, display_ffmpeg=True, debug=False)\n",
    "    if create_gif:\n",
    "        make_gif_ffmpeg(ffmpeg_args, debug=False)\n",
    "    #patrol_cycle(args,ffmpeg_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vL8nOkac767"
   },
   "source": [
    "# Disconnect Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "MMpAcyrYWM_v"
   },
   "outputs": [],
   "source": [
    "skip_disconnect_for_run_all = True #@param {type: 'boolean'}\n",
    "\n",
    "if skip_disconnect_for_run_all == True:\n",
    "    print('Skipping disconnect, uncheck skip_disconnect_for_run_all if you want to run it')\n",
    "else:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "25b221746895226ff7c6b9d8aea8c62a9e808c88b786315a5ba5e4e82d158d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
